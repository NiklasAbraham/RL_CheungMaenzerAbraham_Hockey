{
  "curriculum": {
    "phases": [
      {
        "name": "initial_training",
        "episodes": 3000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {"type": "basic_strong", "weight": 1.0}
      },
      {
        "name": "mixed_opponents",
        "episodes": 7000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "reward_bonus": {
          "N": 100,
          "K": 2000,
          "WIN_BONUS_START": 10.0,
          "WIN_BONUS_FINAL": 1.0,
          "WIN_DISCOUNT_START": 0.92,
          "WIN_DISCOUNT_FINAL": 0.92
        },
        
        "opponent": {
          "type": "weighted_mixture",
          "opponents": [
            {
              "type": "basic_strong", 
              "weight": 0.25
            },
            {
              "type": "self_play", 
              "weight": 0.25,
              "checkpoint": "results/reference_bots/SAC/run_lr1e03_bs256_h128_128_128_4c1f51eb_20260111_140638_vec24.pt",
              "agent_type": "SAC",
              "deterministic": true
            },
            {
              "type": "self_play", 
              "weight": 0.25,
              "checkpoint": "results/reference_bots/TDMPC2/TDMPC2_run_lr3e04_bs512_hencoder_dynamics_reward_termination_q_function_policy_cfce4de1_20260123_210009_ep009200.pt",
              "agent_type": "TDMPC2",
              "deterministic": true
            },
            {
              "type": "self_play", 
              "weight": 0.25,
              "checkpoint": "results/reference_bots/DecoyPolicy/decoy_policy_20260130_125510/models/decoy_policy_final.pt",
              "agent_type": "DECOYPOLICY",
              "deterministic": true
            }
          ]
        }
      },
      {
        "name": "archive_opponents_1",
        "episodes": 2000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "archive"
        },
        "reward_shaping": null,
        "clear_buffer": false
      },
      {
        "name": "checkpoints_1",
        "episodes": 2000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "run_checkpoints",
          "agent_type": "TDMPC2",
          "deterministic": true
        },
        "clear_buffer": false,
        "reward_shaping": null
      },
      {
        "name": "archive_opponents_2",
        "episodes": 2000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "archive"
        },
        "reward_shaping": null,
        "clear_buffer": false
      },
      {
        "name": "checkpoints_2",
        "episodes": 2000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "run_checkpoints",
          "agent_type": "TDMPC2",
          "deterministic": true
        },
        "clear_buffer": false,
        "reward_shaping": null
      },
      {
        "name": "archive_opponents_3",
        "episodes": 2000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "archive"
        },
        "reward_shaping": null,
        "clear_buffer": false
      },
      {
        "name": "checkpoints_3",
        "episodes": 2000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "run_checkpoints",
          "agent_type": "TDMPC2",
          "deterministic": true
        },
        "clear_buffer": false,
        "reward_shaping": null
      },
      {
        "name": "archive_opponents_4",
        "episodes": 5000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "archive"
        },
        "reward_shaping": null,
        "clear_buffer": false
      },
      {
        "name": "checkpoints_4",
        "episodes": 5000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "run_checkpoints",
          "agent_type": "TDMPC2",
          "deterministic": true
        },
        "clear_buffer": false,
        "reward_shaping": null
      },
      {
        "name": "checkpoints_5",
        "episodes": 5000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "run_checkpoints",
          "agent_type": "TDMPC2",
          "deterministic": true
        },
        "clear_buffer": false,
        "reward_shaping": null
      },
      {
        "name": "archive_opponents_5",
        "episodes": 5000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "archive"
        },
        "reward_shaping": null,
        "clear_buffer": false
      },
      {
        "name": "checkpoints_6",
        "episodes": 50000,
        "environment": {"mode": "NORMAL", "keep_mode": true},
        "opponent": {
          "type": "run_checkpoints",
          "agent_type": "TDMPC2",
          "deterministic": true
        },
        "clear_buffer": false,
        "reward_shaping": null
      }
    ]
  },
  "hyperparameters": {
    "learning_rate": 0.0003,
    "batch_size": 512
  },
  "training": {
    "max_episode_steps": 500,
    "updates_per_step": 1,
    "warmup_steps": 5000,
    "reward_scale": 1.0,
    "checkpoint_save_freq": 200
  },
  "agent": {
    "type": "TDMPC2",
    "hyperparameters": {
      "latent_dim": 256,
      "hidden_dim": {
        "encoder": [
          256,
          256,
          256
        ],
        "dynamics": [
          256,
          256,
          256
        ],
        "reward": [
          256,
          256,
          256
        ],
        "termination": [
          256,
          256
        ],
        "q_function": [
          256,
          256,
          256
        ],
        "policy": [
          256,
          256,
          256
        ]
      },
      "num_q": 5,
      "gamma": 0.99,
      "horizon": 8,
      "num_samples": 512,
      "num_iterations": 6,
      "temperature": 0.5,
      "vmin": -10.0,
      "vmax": 10.0,
      "win_reward_bonus": 10.0,
      "win_reward_discount": 0.92,
      "opponent_simulation": {
        "enabled": true,
        "cloning_frequency": 2500,
        "cloning_steps": 5000,
        "cloning_samples": 512,
        "opponent_agents": [
          {
            "type": "TDMPC2",
            "path": "results/reference_bots/TDMPC2/TDMPC2_run_lr3e04_bs512_hencoder_dynamics_reward_termination_q_function_policy_cfce4de1_20260123_210009_ep009200.pt"
          },
          {
            "type": "SAC",
            "path": "results/reference_bots/SAC/run_lr1e03_bs256_h128_128_128_4c1f51eb_20260111_140638_vec24.pt"
          },
          {
            "type": "DECOYPOLICY",
            "path": "results/reference_bots/DecoyPolicy/decoy_policy_20260130_125510/models/decoy_policy_final.pt"
          }
        ]
      }
    }
  }
}
