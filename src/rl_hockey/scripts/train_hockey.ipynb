{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d831ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef02867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import hockey.hockey_env as h_env\n",
    "\n",
    "from rl_hockey.sac import SAC\n",
    "from rl_hockey.common import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = h_env.HockeyEnv(mode=h_env.Mode.TRAIN_SHOOTING)\n",
    "\n",
    "o_space = env.observation_space\n",
    "ac_space = env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c848d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_episodes = 500\n",
    "max_episode_steps = 500\n",
    "updates_per_step = 1\n",
    "warmup_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SAC(o_space.shape[0], action_dim=ac_space.shape[0], noise='pink', max_episode_steps=max_episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a02ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_losses = []\n",
    "actor_losses = []\n",
    "rewards = []\n",
    "steps = 0\n",
    "gradient_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9295ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'hockey-shooting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(range(max_episodes), desc=run_name)\n",
    "for i in pbar:    \n",
    "    total_reward = 0\n",
    "    state, _ = env.reset()\n",
    "\n",
    "    agent.on_episode_start(i)\n",
    "\n",
    "    for t in range(max_episode_steps):\n",
    "        done = False\n",
    "        action = agent.act(state.astype(np.float32))\n",
    "        (next_state, reward, done, trunc, _) = env.step(action)\n",
    "        agent.store_transition((state, action, reward, next_state, done))\n",
    "        agent.store_transition((utils.mirror_state(state), utils.mirror_action(action), reward, utils.mirror_state(next_state), done))          \n",
    "        state = next_state\n",
    "\n",
    "        steps += 1\n",
    "        total_reward += reward\n",
    "\n",
    "        if steps >= warmup_steps / 2:  # mirroring enables 2 transitions per step\n",
    "            stats = agent.train(updates_per_step)\n",
    "\n",
    "            gradient_steps += updates_per_step\n",
    "            critic_losses.extend(stats['critic_loss'])\n",
    "            actor_losses.extend(stats['actor_loss'])\n",
    "\n",
    "        if done or trunc:\n",
    "            break\n",
    "\n",
    "    agent.on_episode_end(i)\n",
    "\n",
    "    rewards.append(total_reward)    \n",
    "    \n",
    "    pbar.set_postfix({\n",
    "        'total_reward': total_reward,\n",
    "        'episode_length': t,\n",
    "    })\n",
    "\n",
    "agent.save(f'../../../models/sac/{run_name}_{gradient_steps//1000}k.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    moving_averages = []\n",
    "    for i in range(len(data)):\n",
    "        window_start = max(0, i - window_size + 1)\n",
    "        window = data[window_start:i + 1]\n",
    "        moving_averages.append(sum(window) / len(window))\n",
    "    \n",
    "    return moving_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e393d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moving_average(rewards, 10))\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Total Reward per Episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moving_average(critic_losses, 100))\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Critic Loss')\n",
    "plt.title('Critic Loss over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moving_average(actor_losses, 100))\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Actor Loss')\n",
    "plt.title('Actor Loss over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fbecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = h_env.HockeyEnv(mode=h_env.Mode.TRAIN_SHOOTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward = 0\n",
    "state, _ = env.reset()\n",
    "for t in range(max_episode_steps):\n",
    "    env.render(mode=\"human\")\n",
    "\n",
    "    done = False\n",
    "    action = agent.act(state.astype(np.float32), deterministic=True)\n",
    "    (next_state, reward, done, trunc, _) = env.step(action)\n",
    "    state = next_state\n",
    "\n",
    "    total_reward += reward\n",
    "\n",
    "    if done or trunc:\n",
    "        break\n",
    "\n",
    "print(f'total_reward: {total_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a47bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-hockey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
